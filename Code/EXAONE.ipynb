{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b79accf5-0ce4-48de-9c93-cb8792a17910",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\javis\\anaconda3\\envs\\exaone_env\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import torch\n",
    "import json\n",
    "from tqdm import tqdm\n",
    "from datasets import load_dataset, get_dataset_config_names\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "\n",
    "def evaluate_model_on_dataset(model_name: str, dataset_name: str, subsets: [], num_samples: int):\n",
    "    \"\"\"\n",
    "    model_name: Hugging Face에서 사용할 모델 이름 (예: \"LGAI-EXAONE/EXAONE-3.5-2.4B-Instruct\")\n",
    "    dataset_name: 데이터셋 이름 (예: \"HAERAE-HUB/KMMLU\")\n",
    "    num_samples: 각 subset에서 평가할 샘플 수\n",
    "    \"\"\"\n",
    "    \n",
    "    model = AutoModelForCausalLM.from_pretrained(\n",
    "        model_name,\n",
    "        torch_dtype=torch.bfloat16,\n",
    "        trust_remote_code=True,\n",
    "        device_map=\"auto\",\n",
    "    )\n",
    "    tokenizer = AutoTokenizer.from_pretrained(model_name)    \n",
    "\n",
    "    result = {}\n",
    "    option_map = {1: \"A\", 2: \"B\", 3: \"C\", 4: \"D\"}\n",
    "    \n",
    "    for subset in tqdm(subsets, desc=\"Evaluating subsets\"):\n",
    "        subset_result = {\"predict\": []}\n",
    "        try:\n",
    "            ds = load_dataset(dataset_name, subset)\n",
    "        except Exception as e:\n",
    "            subset_result[\"predict\"].append(f\"데이터셋 로드 중 오류 발생: {e}\")\n",
    "            result[subset] = subset_result\n",
    "            continue\n",
    "        \n",
    "        test_set = ds[\"test\"]\n",
    "        if test_set.num_rows < num_samples:\n",
    "            samples = test_set\n",
    "        else:\n",
    "            samples = test_set.select(range(num_samples))\n",
    "        \n",
    "        correct = 0\n",
    "        total = len(samples)\n",
    "        \n",
    "        for idx, sample in enumerate(samples):\n",
    "            question = sample[\"question\"]\n",
    "            option_A = sample[\"A\"]\n",
    "            option_B = sample[\"B\"]\n",
    "            option_C = sample[\"C\"]\n",
    "            option_D = sample[\"D\"]\n",
    "            \n",
    "            if isinstance(sample[\"answer\"], int):\n",
    "                true_answer = option_map.get(sample[\"answer\"], \"\")\n",
    "            else:\n",
    "                true_answer = sample[\"answer\"].strip().upper()\n",
    "            \n",
    "            prompt = (\n",
    "                f\"Question: {question}\\n\"\n",
    "                f\"A. {option_A}\\n\"\n",
    "                f\"B. {option_B}\\n\"\n",
    "                f\"C. {option_C}\\n\"\n",
    "                f\"D. {option_D}\\n\"\n",
    "                f\"Answer:\"\n",
    "            )\n",
    "            \n",
    "            input_ids = tokenizer.encode(prompt, return_tensors=\"pt\").to(model.device)\n",
    "            output = model.generate(\n",
    "                input_ids,\n",
    "                max_new_tokens=20,\n",
    "                do_sample=False,\n",
    "                eos_token_id=tokenizer.eos_token_id,\n",
    "            )\n",
    "            generated_text = tokenizer.decode(output[0], skip_special_tokens=True)\n",
    "            \n",
    "            answer_text = generated_text.split(\"Answer:\")[-1].strip()\n",
    "            predicted = \"\"\n",
    "            for char in answer_text:\n",
    "                if char.upper() in [\"A\", \"B\", \"C\", \"D\"]:\n",
    "                    predicted = char.upper()\n",
    "                    break\n",
    "            \n",
    "            if predicted == true_answer:\n",
    "                correct += 1\n",
    "            \n",
    "            predict_str = f\"[{idx+1:03d}] 정답: {true_answer} / 예측: {predicted}\"\n",
    "            subset_result[\"predict\"].append(predict_str)\n",
    "        \n",
    "        accuracy = correct / total if total > 0 else 0\n",
    "        subset_result[\"accuracy\"] = accuracy\n",
    "        result[subset] = subset_result\n",
    "\n",
    "    all_accuracies = [v[\"accuracy\"] for v in result.values() if \"accuracy\" in v]\n",
    "    mean_accuracy = sum(all_accuracies) / len(all_accuracies) if all_accuracies else 0\n",
    "    print(f\"Mean Accuracy across all subsets: {mean_accuracy:.2%}\")\n",
    "    \n",
    "    # 결과를 JSON 파일로 저장\n",
    "    with open(\"results.json\", \"w\", encoding=\"utf-8\") as f:\n",
    "        json.dump(result, f, indent=4, ensure_ascii=False)\n",
    "        \n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5f376607-e94d-4f86-b4ec-f342fec5841a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** Evaluation of HAERAE-HUB/KMMLU ***\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading checkpoint shards: 100%|█████████████████████████████████████████████████████████| 2/2 [00:07<00:00,  3.82s/it]\n",
      "Evaluating subsets: 100%|██████████████████████████████████████████████████████████████| 45/45 [29:33<00:00, 39.40s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Accuracy across all subsets: 41.89%\n",
      "Accuracy on Accounting : 37.00%\n",
      "Accuracy on Agricultural-Sciences : 33.20%\n",
      "Accuracy on Aviation-Engineering-and-Maintenance : 44.10%\n",
      "Accuracy on Biology : 35.60%\n",
      "Accuracy on Chemical-Engineering : 41.10%\n",
      "Accuracy on Chemistry : 40.67%\n",
      "Accuracy on Civil-Engineering : 41.30%\n",
      "Accuracy on Computer-Science : 66.30%\n",
      "Accuracy on Construction : 36.40%\n",
      "Accuracy on Criminal-Law : 30.00%\n",
      "Accuracy on Ecology : 49.80%\n",
      "Accuracy on Economics : 40.77%\n",
      "Accuracy on Education : 46.00%\n",
      "Accuracy on Electrical-Engineering : 36.40%\n",
      "Accuracy on Electronics-Engineering : 53.60%\n",
      "Accuracy on Energy-Management : 30.40%\n",
      "Accuracy on Environmental-Science : 34.70%\n",
      "Accuracy on Fashion : 44.30%\n",
      "Accuracy on Food-Processing : 40.40%\n",
      "Accuracy on Gas-Technology-and-Engineering : 39.80%\n",
      "Accuracy on Geomatics : 42.20%\n",
      "Accuracy on Health : 50.00%\n",
      "Accuracy on Industrial-Engineer : 44.90%\n",
      "Accuracy on Information-Technology : 64.20%\n",
      "Accuracy on Interior-Architecture-and-Design : 54.00%\n",
      "Accuracy on Law : 38.60%\n",
      "Accuracy on Machine-Design-and-Manufacturing : 43.50%\n",
      "Accuracy on Management : 44.40%\n",
      "Accuracy on Maritime-Engineering : 44.17%\n",
      "Accuracy on Marketing : 68.70%\n",
      "Accuracy on Materials-Engineering : 39.80%\n",
      "Accuracy on Mechanical-Engineering : 39.10%\n",
      "Accuracy on Nondestructive-Testing : 42.00%\n",
      "Accuracy on Patent : 41.00%\n",
      "Accuracy on Political-Science-and-Sociology : 42.33%\n",
      "Accuracy on Psychology : 35.00%\n",
      "Accuracy on Public-Safety : 38.80%\n",
      "Accuracy on Railway-and-Automotive-Engineering : 34.80%\n",
      "Accuracy on Real-Estate : 37.50%\n",
      "Accuracy on Refrigerating-Machinery : 36.20%\n",
      "Accuracy on Social-Welfare : 45.40%\n",
      "Accuracy on Taxation : 31.00%\n",
      "Accuracy on Telecommunications-and-Wireless-Technology : 58.20%\n",
      "Accuracy on Korean-History : 28.00%\n",
      "Accuracy on Math : 19.33%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "model_name = \"LGAI-EXAONE/EXAONE-3.5-2.4B-Instruct\"\n",
    "dataset_name = \"HAERAE-HUB/KMMLU\"\n",
    "subsets = get_dataset_config_names(dataset_name)\n",
    "num_samples = 3000\n",
    "\n",
    "print(f\"*** Evaluation of {dataset_name} ***\")\n",
    "results = evaluate_model_on_dataset(model_name, dataset_name, subsets, num_samples)\n",
    "for subset in subsets:\n",
    "    print(f\"Accuracy on {subset} : {results[subset]['accuracy']:.2%}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6400f592-7452-4737-918a-9c31e8683860",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KMMLU Benchmark Score: 43.16%\n"
     ]
    }
   ],
   "source": [
    "# results.json 파일 불러오기\n",
    "with open(\"results.json\", \"r\", encoding=\"utf-8\") as f:\n",
    "    results = json.load(f)\n",
    "\n",
    "total_correct = 0\n",
    "total_samples = 0\n",
    "\n",
    "# 각 subset에 대해, 맞춘 샘플 수(accuracy * 샘플 수)와 전체 샘플 수를 누적합산\n",
    "for subset, data in results.items():\n",
    "    subset_samples = len(data[\"predict\"])  # 해당 subset의 총 샘플 수\n",
    "    subset_accuracy = data[\"accuracy\"]       # 해당 subset의 정확도\n",
    "    total_correct += subset_samples * subset_accuracy\n",
    "    total_samples += subset_samples\n",
    "\n",
    "# 전체 정확도 계산 (benchmark score)\n",
    "kmmlu_score = total_correct / total_samples\n",
    "\n",
    "print(\"KMMLU Benchmark Score: {:.2%}\".format(kmmlu_score))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3929722-1cbd-430e-9d07-35345306c6be",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Etc."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4534ca76-d763-43eb-9036-5a8d1001ce20",
   "metadata": {},
   "source": [
    "```\n",
    "conda env remove -n exaone_env\n",
    "conda create -n exaone_env python=3.9 -y\n",
    "conda activate exaone_env\n",
    "conda install pytorch torchvision torchaudio pytorch-cuda=12.1 -c pytorch -c nvidia\n",
    "pip install transformers ipykernel accelerate\n",
    "python -m ipykernel install --user --name exaone_env --display-name EXAONE\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e535c055-4ed0-4b4f-a24c-5ce47f7c1365",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "print(torch.cuda.is_available())\n",
    "print(torch.cuda.device_count())\n",
    "print(torch.cuda.current_device())\n",
    "print(torch.cuda.get_device_name(torch.cuda.current_device()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "939f6929-6304-4d77-b080-76f22194b01a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "print(\"PyTorch에서 사용중인 CUDA 버전:\", torch.version.cuda)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "676e575f-602b-4631-8a23-01f06ed303e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import transformers\n",
    "print(transformers.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "49dfdc19-0ebb-406f-bf03-771e6c4fa9ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "사용 가능한 config (subset) 목록:\n",
      " ['date_understanding', 'context_definition_alignment', 'proverb_unscrambling', '2_digit_multiply', '3_digit_subtract', 'gsm8k_ko']\n",
      "Subset의 수 6\n",
      "date_understanding 475\n",
      "context_definition_alignment 439\n",
      "proverb_unscrambling 672\n",
      "2_digit_multiply 1000\n",
      "3_digit_subtract 1000\n",
      "gsm8k_ko 250\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset, get_dataset_config_names\n",
    "\n",
    "# 1. 사용 가능한 config (subset) 목록 불러오기\n",
    "dataset_name = \"HAERAE-HUB/HAE_RAE_BENCH_2.0\"\n",
    "configs = get_dataset_config_names(dataset_name)\n",
    "print(\"사용 가능한 config (subset) 목록:\\n\", configs)\n",
    "print(\"Subset의 수\", len(configs))\n",
    "\n",
    "# 2. 각 config별로 데이터셋 로드 및 test split 샘플 수 확인\n",
    "for config in configs:\n",
    "    try:\n",
    "        dataset = load_dataset(dataset_name, config)\n",
    "        if \"test\" in dataset:\n",
    "            test_dataset = dataset[\"test\"]\n",
    "            print(config, test_dataset.num_rows)\n",
    "        else:\n",
    "            print(\"해당 config에 test split이 존재하지 않습니다.\")\n",
    "    except Exception as e:\n",
    "        print(f\"데이터셋 로드 중 오류 발생: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5497b010-d383-48f9-bbcf-23bed288b451",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "\n",
    "# model_name = \"LGAI-EXAONE/EXAONE-3.5-2.4B-Instruct\"\n",
    "\n",
    "# model = AutoModelForCausalLM.from_pretrained(\n",
    "#     model_name,\n",
    "#     torch_dtype=torch.bfloat16,\n",
    "#     trust_remote_code=True,\n",
    "#     device_map=\"auto\"\n",
    "# )\n",
    "# tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "\n",
    "# # Choose your prompt\n",
    "# prompt = \"스스로를 자랑해 봐\"       # Korean example\n",
    "\n",
    "# messages = [\n",
    "#     {\"role\": \"system\", \n",
    "#      \"content\": \"You are EXAONE model from LG AI Research, a helpful assistant.\"},\n",
    "#     {\"role\": \"user\", \"content\": prompt}\n",
    "# ]\n",
    "# input_ids = tokenizer.apply_chat_template(\n",
    "#     messages,\n",
    "#     tokenize=True,\n",
    "#     add_generation_prompt=True,\n",
    "#     return_tensors=\"pt\"\n",
    "# )\n",
    "\n",
    "# output = model.generate(\n",
    "#     input_ids.to(\"cuda\"),\n",
    "#     eos_token_id=tokenizer.eos_token_id,\n",
    "#     max_new_tokens=128,\n",
    "#     do_sample=False,\n",
    "# )\n",
    "\n",
    "# print(tokenizer.decode(output[0]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "EXAONE",
   "language": "python",
   "name": "exaone_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
